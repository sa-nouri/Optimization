{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ao_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ne5Ek0Yhcz99"
      },
      "outputs": [],
      "source": [
        "#@title Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "num_datapoints = int(1e3)\n",
        "img_size = int(28)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creating clusters and Computing D\n",
        "\n",
        "num_datapoints = int(1e3)\n",
        "num_clusters = int(3)\n",
        "clusters_std = float(1.0)\n",
        "\n",
        "features, labels = make_blobs(n_samples=num_datapoints, centers=num_clusters, \n",
        "                                    cluster_std=clusters_std, random_state=42)\n",
        "\n",
        "D = euclidean_distances(features, features)\n",
        "s = num_clusters\n",
        "\n",
        "clusters = np.unique(labels)\n",
        "\n",
        "for cluster in clusters:\n",
        "\trow_ix = np.where(labels == cluster)\n",
        "\tplt.scatter(features[row_ix, 0], features[row_ix, 1])\n",
        "\n",
        "plt.grid(True)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sZGkfoyZkM8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare data points\n",
        "\n",
        "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "trainX = trainX.reshape((trainX.shape[0], img_size, img_size, 1))\n",
        "\n",
        "idx = np.random.choice(testX.shape[0], num_datapoints, replace=False)\n",
        "testX = testX[idx]\n",
        "testY = testY[idx]\n",
        "testX = testX.reshape((testX.shape[0], img_size, img_size, 1))\n",
        "\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "m_v2C85olOQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creating Classification model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3),\n",
        "                 padding='same',\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_uniform', \n",
        "                 input_shape=(img_size, img_size, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, \n",
        "           epsilon=1e-07, amsgrad=False)\n",
        "model.compile(optimizer=opt, \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P35TQ4nwABrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model training\n",
        "\n",
        "trainX = trainX /255.0\n",
        "testX = testX /255.0\n",
        "\n",
        "epochs = 14 #@param {}\n",
        "batch_size = 64 #@param {}\n",
        "history = model.fit(trainX, trainY, \n",
        "          epochs=epochs, \n",
        "          batch_size=batch_size, \n",
        "          validation_split=0.2,\n",
        "          shuffle=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8uIe1aMkMsGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate test dataset\n",
        "\n",
        "model.evaluate(testX, testY)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aveWnPUlqa1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot loss\n",
        "history = history.history\n",
        "plt.plot(history['loss'], 'b')\n",
        "plt.plot(history['val_loss'], 'r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.grid(True)\n",
        "plt.title('Loss')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "B3uvOmPjdp6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot accuracy\n",
        "\n",
        "plt.plot(history['accuracy'], 'b')\n",
        "plt.plot(history['val_accuracy'], 'r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AddfK4zBeDNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Computing posterior probabilities and D\n",
        "\n",
        "post_prob = model.predict(testX)\n",
        "D = euclidean_distances(post_prob, post_prob)\n",
        "np.save('distance.npy', D)\n"
      ],
      "metadata": {
        "id": "CAIRz3YiWqIK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Heatmap of Distance matrix\n",
        "\n",
        "# import seaborn as sns\n",
        "\n",
        "# ax = sns.heatmap(uniform_data, linewidth=0.5)\n",
        "# plt.show()\n",
        "D = np.load('datad.npy')\n",
        "plt.imshow(D, cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "m0iVaA9XrCQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inexact ALM initializations\n",
        "\n",
        "tau_f , tau_s  = 1e-4, 1e-4   # Stopping thresholds \n",
        "K = int(2e1)\n",
        "b = 2.0\n",
        "seq_betha = np.sort(np.random.randint(low=1, high=14, size=(K, )))\n",
        "seq_betha = np.sort(b**seq_betha)\n",
        "sigma = [0.1]\n",
        "\n",
        "# Clustering parameters\n",
        "num_datapoints = 200\n",
        "r = 20\n",
        "ones = np.ones((num_datapoints, 1))\n",
        "\n",
        "# BP parameters\n",
        "n = int(3e3)\n",
        "d = int(2e1)\n",
        "std_noise = float(1e-6)\n",
        "mean, std = 0, 1\n",
        "noise = np.random.normal(loc=mean, scale=std_noise, size=(n, 1))\n",
        "\n",
        "# Generalized Eigenvalue parameters\n",
        "n_eig = int(1e3)\n",
        "p1 = 1\n",
        "p2 = 0.0025\n",
        "\n",
        "data = {'gaussian': np.random.normal(loc=mean, scale=std, size=(n_eig, n_eig)),\n",
        "        'poly': np.diag(np.arange(1.0, n_eig+1) ** (-p1)),\n",
        "        'exp': np.diag(np.arange(1.0, n_eig+1) ** (-p2))}\n",
        "\n",
        "def update_tolerance(betha):\n",
        "    return 1/betha\n",
        "\n",
        "def init_clustering(constraint_func):\n",
        "    x = np.random.rand(num_datapoints * r, 1)\n",
        "    y = np.random.rand(num_datapoints, 1)\n",
        "    D = np.load('datad.npy')\n",
        "    # D = np.load('distance.npy')\n",
        "    D = D[0:num_datapoints, 0:num_datapoints]\n",
        "    return x, y, D\n",
        "\n",
        "def init_bp():\n",
        "    B = np.random.normal(loc=mean, scale=std, size=(n, d))\n",
        "    x = np.random.rand(2 * d, 1)\n",
        "    y = np.random.rand(n, 1)\n",
        "    B_bar = np.concatenate((B, -B), axis=1)\n",
        "    return x, y, B, B_bar\n",
        "\n",
        "def init_gen_eig(mode):\n",
        "    C = data[mode]\n",
        "    C = (C + C.T) * 0.5\n",
        "    B = np.random.rand(n_eig, n_eig)\n",
        "    B = np.dot(B, B.T)\n",
        "    B = B + np.sqrt(n_eig/4) * np.eye(n_eig)\n",
        "    x = np.random.rand(n_eig, 1)\n",
        "    y = np.random.rand(1, 1)\n",
        "    return x, y, C, B\n",
        "\n",
        "def clustering_func(x):\n",
        "    U = x.reshape((num_datapoints, r))\n",
        "    Y = np.matmul(U, U.T)\n",
        "    A = np.matmul(Y, ones) - ones\n",
        "    return np.trace(np.matmul(D, Y)) + np.dot(A.T, y) + (betha/2) * np.dot(A.T, A)\n",
        "\n",
        "def bp_func(x):\n",
        "    # arr1, arr2 = x.reshape(2, d)[0, :], x.reshape(2, d)[1, :]\n",
        "    arr1 = x[0:d]\n",
        "    arr2 = x[d:]\n",
        "    z = (arr1 ** 2) - (arr2 **2)\n",
        "    b = np.matmul(B, z[:, None]) + noise\n",
        "    A = np.matmul(B_bar, x**2)[:, None] - b\n",
        "    return np.dot(x.T, x) + np.dot(A.T, y) + (betha/2) * np.dot(A.T, A)\n",
        "\n",
        "def eig_func(x):\n",
        "    f = np.matmul(np.matmul(x.T, C), x)\n",
        "    Ac = np.matmul(np.matmul(x.T, B), x) - 1\n",
        "    lag =  Ac * y\n",
        "    penalty = betha/2 * np.dot(Ac.T, Ac)\n",
        "    return f + lag + penalty\n",
        "\n",
        "def grad_bp(x):\n",
        "    df = 2 * x[:, None]\n",
        "    DA = np.matmul(B_bar, np.diag(x))\n",
        "    dlag_coe = 2 *  np.matmul(DA.T, y)\n",
        "    dpenalty = betha/2 * np.matmul(DA.T, constraint_func(x))\n",
        "    return df + dlag_coe + dpenalty\n",
        "\n",
        "def grad_eig(x):\n",
        "    df = 2 * np.matmul(C, x[:, None])\n",
        "    dA = np.matmul(B, x[:, None])\n",
        "    dlag = 2 * y * dA\n",
        "    dp = betha/2 * dA * np.matmul(np.matmul(x.T, B), x) - 1\n",
        "    return df + dlag + dp\n",
        "\n",
        "def hess_bp(x):\n",
        "    h1 = 2*np.eye(40) + np.matmul(DA.T, DA) * np.dot(y.T, y)\n",
        "    h2 = np.matmul(B_bar.T, B_bar) * np.diag(x) * betha/2\n",
        "    return (h1 + h2 )\n",
        "\n",
        "def hess_eig(x):\n",
        "    h1 = (2 * C + 2 * B * y)\n",
        "    h2 = (betha/2 * (B * np.matmul(np.matmul(x.T, B), x) - 1) + np.matmul(dA, dA.T))\n",
        "    return h1 + h2\n",
        "\n",
        "def calc_constraint_clustering(x):\n",
        "    U = x.reshape((num_datapoints, r))\n",
        "    Y = np.matmul(U, U.T)\n",
        "    A = np.matmul(Y, ones) - ones\n",
        "    return A\n",
        "\n",
        "def calc_constraint_BP(x):\n",
        "    arr1, arr2 = x.reshape(2, d)[0, :], x.reshape(2, d)[1, :]\n",
        "    z = (arr1 ** 2) - (arr2 **2)\n",
        "    b = np.matmul(B, z)[:, None] + noise\n",
        "    return np.matmul(B_bar, x**2)[:, None] - b\n",
        "\n",
        "def calc_constraint_eig(x):\n",
        "    return np.matmul(np.matmul(x.T, B), x) - 1\n",
        "\n",
        "def inexact_primal_sol(func, x, y, betha, eps, method='l-bfgs', grad=None, hess=None):\n",
        "    if method == 'l-bfgs':\n",
        "        result = minimize(func, x, method='L-BFGS-B', jac=grad,\n",
        "                          options={'eps': eps})\n",
        "    return result['x'], np.abs(result['fun'])\n",
        "\n",
        "def update_dual_step_size(calc_constraint, x, norm_A1, k):\n",
        "    A = calc_constraint(x)\n",
        "    norm_A = np.dot(A.T, A)\n",
        "    numerator = norm_A1 * (np.log10(2)**2)\n",
        "    denominator = norm_A * (k+1) * (np.log10(k+2)**2)\n",
        "    up_value = numerator/denominator\n",
        "    return sigma[0] * np.min([up_value, 1])\n",
        "\n",
        "def update_dual_ascent(calc_constraint, y, sigma, x):\n",
        "    A = calc_constraint(x)\n",
        "    return y + sigma * A\n",
        "\n",
        "\n",
        "def stopping_criterion(epsilon, g=False,\n",
        "                       quit=False, order='first',\n",
        "                       grad=None, hess=None,\n",
        "                       constraint_value=None):\n",
        "    A_val = 0 \n",
        "    if g:\n",
        "        grad = np.where(grad < 0, 0, grad)\n",
        "    if quit:\n",
        "        A_val = np.linalg.norm(constraint_value)\n",
        "    if (order == 'first'):\n",
        "        if (np.linalg.norm(grad) + A_val <= epsilon):\n",
        "            print('First order stopping criterion')\n",
        "            return 1\n",
        "    if (order == 'second'):\n",
        "        if( min(np.linalg.eigvalsh(hess)) >= -epsilon):\n",
        "            print('Second order stopping criterion')\n",
        "            return 2\n",
        "    return 0\n",
        "\n",
        "def sel_example(example):\n",
        "    if example == 'clustering':\n",
        "        return clustering_func, calc_constraint_clustering\n",
        "    elif example == 'bp':\n",
        "        return bp_func, calc_constraint_BP, grad_bp, hess_bp\n",
        "    elif example == 'eig':\n",
        "        return eig_func, calc_constraint_eig, grad_eig, hess_eig\n",
        "\n",
        "\n",
        "def previous_sol(func, x, y, betha, eps, method='l-bfgs', grad=None, hess=None):\n",
        "    stopping_criterion = 1\n",
        "    while stopping_criterion != 0:\n",
        "        if method == 'l-bfgs':\n",
        "            result = minimize(func, x, method='L-BFGS-B', jac=grad,\n",
        "                            options={'eps': eps})\n",
        "            x = result['x']\n",
        "            stop_criteria = stopping_criterion(epsilon=tau_f, g=False, quit=False,\n",
        "                        order='first',\n",
        "                        grad= -grad(x), \n",
        "                        constraint_value=constraint_func(x), hess=hess)\n",
        "    return result['x'], np.abs(result['fun'])"
      ],
      "metadata": {
        "id": "B104Gn3FKocV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process\n",
        "\n",
        "# def iALM(example):\n",
        "example='bp'\n",
        "objective_vals = []\n",
        "x_vals = []\n",
        "y_vals = []\n",
        "obj, constraint_func, grad, hess = sel_example(example=example)\n",
        "if example == 'clustering':\n",
        "    x, y, D = init_clustering(constraint_func)\n",
        "    A1 = constraint_func(x)\n",
        "    norm_A1 = np.dot(A1.T, A1)[0]\n",
        "elif example == 'bp':\n",
        "    x, y, B, B_bar = init_bp()\n",
        "    A1 = constraint_func(x[:,0])\n",
        "    norm_A1 = np.dot(A1.T, A1)[0]\n",
        "elif example == 'eig':\n",
        "    x, y, C, B = init_gen_eig('exp')\n",
        "    A1 = constraint_func(x[:,0])\n",
        "    norm_A1 = np.dot(A1.T, A1)\n",
        "for k in range(K):\n",
        "    betha = seq_betha[k]\n",
        "    epsilon = update_tolerance(betha)\n",
        "    x, f_new = inexact_primal_sol(obj, x, y, betha, epsilon,\n",
        "                                    method='l-bfgs')\n",
        "    \n",
        "    sigma_new = update_dual_step_size(constraint_func, x, norm_A1, k)\n",
        "    y = update_dual_ascent(constraint_func, y, sigma[k], x)\n",
        "    x_vals.append(list(x))\n",
        "    y_vals.append(list(y[:, 0]))\n",
        "    sigma.append(sigma_new)\n",
        "    objective_vals.append(f_new[0][0])\n",
        "    stop_criteria = stopping_criterion(epsilon=tau_f, g=False, quit=False,\n",
        "                       order='first',\n",
        "                       grad= -grad_bp(x), constraint_value=constraint_func(x))\n",
        "    if stop_criteria:\n",
        "        break\n",
        "\n",
        "# return x_vals, y_vals, objective_vals, sigmadogleg"
      ],
      "metadata": {
        "id": "6019FFJVVN7b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot Objective Residual\n",
        "\n",
        "diff = abs(objective_vals - objective_vals[-1])\n",
        "iters = np.arange(0, len(objective_vals))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.semilogy(iters, diff, 'b')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('|f(x)-f*|')\n",
        "plt.grid(True)\n",
        "plt.title('Objective Residual')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oKpja4oxz6k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot Feasibility\n",
        "\n",
        "norm_Ax = []\n",
        "for item in x_vals:\n",
        "    Ax = constraint_func(np.array(item))\n",
        "    norm_Ax.append(np.dot(Ax.T, Ax))\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.semilogy(iters, np.array(norm_Ax), 'b')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('||A(x)||')\n",
        "plt.grid(True)\n",
        "plt.title('Feasibility')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0dLZ7SIg4Nqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  plot eigenvalues\n",
        "\n",
        "eigs_C = np.linalg.eigvalsh(C)\n",
        "eigs_B = np.linalg.eigvalsh(B)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(-np.sort(-eigs_C), 'b--')\n",
        "# plt.plot(-np.sort(-eigs_B), 'r-')\n",
        "plt.xlabel('i')\n",
        "plt.ylabel('eigenvalues')\n",
        "plt.title('Exponential decay')\n",
        "# plt.legend(['Eigenvalue-C', 'Eigenvalue-B'])\n",
        "plt.grid('True')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XmTJNqc65D6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title previous minimizing\n",
        "\n",
        "sigma = [0.1]\n",
        "for k in range(K):\n",
        "    betha = seq_betha[k]\n",
        "    epsilon = update_tolerance(betha)\n",
        "    x, f_new = inexact_primal_sol(clustering_func, x, y, betha, method='l-bfgs')\n",
        "    print(f_new)\n",
        "    objective_vals.append(f_new)\n",
        "    x_vals.append(list(x))\n",
        "    sigma_new = update_dual_step_size(x, norm_A1, k)\n",
        "    y = update_dual_ascent(y, sigma_new, x)\n",
        "    y_vals.append(list(y[:, 0]))\n",
        "    sigma.append(sigma_new)\n",
        "    print(k)"
      ],
      "metadata": {
        "id": "CeG8jVi_zahz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}